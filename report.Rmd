---
output: 
  html_document: 
    df_print: default
    toc: yes
---
<style type="text/css">
@import url("http://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css");
</style>
<meta name="viewport" content="width=device-width, initial-scale=1">
<center>![avatar](store.png)</center> 

# Google Play Store Data Analysis Report
## 0. Introduction
This data set is scraped from Google Play Store. There are 13 features that provide detailed information about App in Google Play Store, including the name, category, Rating, Reviews and so on.
<br>
<HR>
In the report, I'm going to analyze the data in the following 5 aspects:
<br>
1. **Import packages**: set up the environment for the whole project
<br>
2. **Exploratory Data Analysis**: Analyze and visualize the data
<br>
3. **Linear Model Analysis**: use linear model to fit the data
<br>
4. **Tree-based Model Analysis**: use tree-based model to fit the data
<br>
5. **Summary**: Make a conclusion
<br>
<HR>
In this data set, I want to find how to predict game **reviews**(continuous,linear model) and **Installs**(discrete,tree-based model) using the known information.

## 1. Import Packages
```{r,message=FALSE,warning=FALSE}
# creat a new environment
rm(list=ls())
# import packages 
library(MASS)
library(readr)
library(ggplot2)
library(corrplot)
library(Amelia)
library(reshape2)
library(caret)
library(caTools)
library(dplyr)
library(tidyr)
library(plotly)
library(texreg)
library(reshape2)
library(leaps)
library(rpart)
library(rpart.plot)
library(e1071)
google_data <- read_csv('googleplaystore.csv')
head(google_data)
```
## 2. Data Cleaning
- Draw the data missmap  
- Change data type  
- Get the summary of data
```{r,message=FALSE,warning=FALSE}
# Draw the data missmap
missmap(google_data, legend=FALSE)
```  

The main NA data are in the 'Rating' column, so we decided to use drop_na() function to drop the row containing NA data.
```{r}
# drop the null data from the original data set
google_data <- drop_na(google_data)
# see first few lines of data
head(google_data)
# see the data type of the data set
str(google_data)
```  
As we directly import the data set from csv. file, the data type of these columns are wrong. We need correct them manually.
```{r}
# change data type of the original data set
google_data$App <- as.character(google_data$App)
google_data$Reviews <- as.numeric(as.character(google_data$Reviews))
google_data$Price <- as.numeric(as.character(google_data$Price))
google_data$Size <- as.numeric(google_data$Size)
google_data$`Current Ver` <- as.character(google_data$`Current Ver`)
google_data$`Android Ver` <- as.character(google_data$`Android Ver`)
google_data$Category <- as.factor(google_data$Category)
google_data$Genres <- as.factor(google_data$Genres)
google_data$`Content Rating` <- as.factor(google_data$`Content Rating`)
google_data$Installs <- as.numeric(google_data$Installs)
google_data <- google_data[-which(names(google_data)=='Type')]
# get a summary information of the data set
summary(google_data)
```

## 3. Exploraroy Data Analysis
We intend to analyze the data in the following aspects  

- The category with highest market share  
- The distribution of Apps  
- The rating in different categories  
- The reviews in different categories  

### The category with highest market share in the market
```{r}
attach(google_data)
# Compute Market Share of every Categories
share_count <- c()
index <- 1
# the loop is to calculate the market share of every category
for( i in levels(Category)){
  temp_df <- google_data[which(Category == i),]
  share_count[index] <- dim(temp_df)[1]
  index <- index + 1
}
df <- data.frame(levels(Category),share_count)
df <- df[order(df$share_count,decreasing = TRUE),]
p <- plot_ly(df,labels=~levels.Category.,values=~share_count,type='pie')
p

```
<font color='orange'>**Finding**</font>
<br>
1. nearly half of the market share was dominated by games from 
**'Family'(20.9%),'Game'(12.6%),'Tools'(8.16%), 'Medical'( 4.22%),'Lifestyle'(3.63%)** categories. 
<br>
2. the distribution of market share is uneven. the gap between the best and the worst category is very large

### The distributions of Apps
```{r,message=FALSE,warning=FALSE}
# draw the ggplot image 
# image_2 is the distribution of App rating 
image_2 <- ggplotly(ggplot(google_data, aes(x=Rating)) + geom_area(stat="bin",fill='#1E90FF') +geom_vline(xintercept = mean(Rating),col='red',lty=3,lwd = 1 )+xlab("Rating Score")+ylab("Number of App") +theme_bw() +theme(plot.title = element_text(hjust = 0.5),axis.text.y = element_text(angle=90,hjust=1)))
# image_3 is the distribution of App reviews
image_3 <- ggplotly(ggplot(google_data, aes(x=Reviews)) + geom_area(stat="bin",fill='#98FB98') +geom_vline(xintercept = mean(Reviews),col='red',lty=3,lwd = 1 )+xlab("Reviews Amount")+ylab("Number of App") + ggtitle("Distribution of Different Features") +theme_bw() +theme(plot.title = element_text(hjust = 0.5),axis.text.y = element_text(angle=90,hjust=1)))
# image_4 is the distribution of App size 
image_4 <- ggplotly(ggplot(google_data, aes(x=Size)) + geom_area(stat="bin",fill='#DAA520') +geom_vline(xintercept = mean(Size),col='red',lty=3,lwd = 1 )+xlab("Reviews Amount")+ylab("Number of App") +theme_bw() +theme(plot.title = element_text(hjust = 0.5),axis.text.x = element_text(angle = 90, hjust = 1),axis.text.y = element_text(angle=90,hjust=1)))
# image_5 is the distribution of App installs
image_5 <- ggplotly(ggplot(google_data, aes(x=Installs)) + geom_area(stat="bin",fill='#D2691E') +geom_vline(xintercept = mean(Installs),col='red',lty=3,lwd = 1 )+xlab("Reviews Amount")+ylab("Number of App") +theme_bw() +theme(plot.title = element_text(hjust = 0.5),axis.text.x = element_text(angle = 90, hjust = 1),axis.text.y = element_text(angle=90,hjust=1)))
subplot(image_2,image_3,image_4,image_5,nrows=2, margin = 0.05)
```
<font color='orange'>**Finding**</font>
<br>
1. Most apps do well in the game market and get an average score of **4.17**;the low score area and high score area are both very samll
<br>
2. Most apps receive reviews lower in the interval **[7000,300000]**
<br>
3. The size of the game is usually smalle than 100M
<br>
4. The mean install amount is **8458767**

### The rating in different categories
```{r,warning=FALSE}
attach(google_data)
# compute the average Rating score by group
cat_data <- group_by(google_data,Category)
data <- summarise(cat_data,count = n(),rating_score = mean(Rating))
# sort the data by descending order
data <- data[order(data$rating_score,decreasing = TRUE),]
# iamge_6 is the different rating grouped by 'categories'
image_6 <- ggplot(data = data,aes(x = levels(Category),y = rating_score,fill=levels(Category))) + geom_bar(stat = 'identity', position = 'dodge')+theme(axis.text.x = element_text(angle = 90, hjust = 1))+geom_hline(aes(yintercept=4), colour="white", linetype="dashed")+theme(panel.border = element_blank())+ coord_cartesian(ylim=c(3.5, 4.5)) +xlab("Categories in Google Play Store")+ylab("Rating")+ ggtitle("Rating in Different Categories") +theme(plot.title = element_text(hjust = 0.5))+scale_fill_discrete(name="Category")
ggplotly(image_6)
```
<font color='orange'>**Finding**</font>
<br>
1. There is some differece in 'Rating' among categories, but the difference is way too small
<br>
2. 'Art and Design' Category always has the highest Rating score, and 'Auto and Vehicles' Category cathes up

### The reviews in different categories
```{r}
# calculate the reviews grouped by 'categories'
cat_data <- group_by(google_data,Category)
cat_data <- summarise(cat_data,count = n(),reviews = sum(Reviews))
# 'p' respresents 'Reviews' grouped by 'categories'
p <- google_data %>%
  plot_ly(
    x = ~Category,
    y = ~Reviews,
    split = ~Category,
    type = 'violin',
    box = list(
      visible = T
    ),
    meanline = list(
      visible = T
    )
  ) %>% 
  layout(
    title = "Reviews in Different Categories",
    xaxis = list(
      title = "Categories in Google Play Store"
    ),
    yaxis = list(
      title = "Reviews",
      zeroline = F
    )
  )
p
```
<font color='orange'>**Finding**</font>
<br>
1. Almost all app categories perform decently. Health and Fitness and Books and Reference produce the highest quality
<br>
2. apps with 50% apps having a rating greater than 4.5.
<br>
3. On the contrary, 50% of apps in the Dating category have a rating lesser than the average rating.
<br>
```{r}
# Fitted line by 'Rating' and 'Reviews'
line_1 <- lm(Rating~Reviews,data = google_data)
new <- data.frame(google_data$Reviews)
y <- predict(line_1,newdata = new)
p <- plot_ly(data = google_data, x = ~google_data$Reviews, y = ~google_data$Rating,type = 'scatter',name='Actual Points') %>%add_trace(y = ~y, name = 'Linear Regression', mode = 'lines')%>% 
  layout(
    title = "Rating vs Reviews",
    xaxis = list(
      title = "Reviews"
    ),
    yaxis = list(
      title = "Rating",
      zeroline = F
    )
  )
p
```
<font color='orange'>**Finding**</font>
<br>
1. Rating and Reviews seems not have a very strong relationship
<br>
2. The fitted line shows that every increase in Reviews only leads to limited increase in Rating score
<br>
```{r}
# change the data type and pick the numeric ones from all the columns
google_data$Category <- as.numeric(google_data$Category)
google_data$Genres <- as.numeric(google_data$Genres)
google_data$`Content Rating` <- as.numeric(google_data$`Content Rating`)
google_num <- select_if(google_data,is.numeric,genres = google_data$Genres,content_rating = google_data$`Content Rating`)
google_num <- mutate(google_num,Category=google_data$Category)

```

### T Test
**Claim:The average value of 'rating' equals to 4**
```{r}
# Test if the average value of 'rating' equals to 4 
t.test(Rating,mu = 4,alt = "two.sided", conf=0.95,data=google_data)
```
<font color='orange'>**Finding**</font>
<br>
1. p-value in T-Test is less than 0.05, which means our claim can be accepted in the 95% cofidencee interval
<br>

## 4. Linear Model Analysis
- Correlation Map
- Polynomial Model
- polynomial Model with interactions
- T Test
- compare the modles in 2 and 3
- visulaize the performance of the two models

### Correlation Map
```{r}
#draw the correlation map of different features in numeric columns of google_data
cor_google <- cor(google_num)
melted_cor <- melt(cor_google)
cor_image <- ggplot(data = melted_cor, aes(x=Var1, y=Var2, fill=value)) + geom_tile() +xlab("")+ylab("")+ ggtitle("The Correlation of Different Features") +theme(plot.title = element_text(hjust = 0.5)) 
ggplotly(cor_image)
```
Here I change the data type of some columns again and visulaize the correlation of them using the map above
The brighter the square is, the higher relationship the two features will be. 
<br>
<font color='orange'>**Finding**</font>
<br>
1. 'Reviews and Installs' / 'Genres and Category' have a significant positive relationship
<br>
2. Most of the features are not so tightly correlated
<br>

### Polynomial Model
```{r}
#set a seed 
set.seed(123)
#Split the data to train set and test set
split = sample.split(google_num,SplitRatio =0.75)
train = subset(google_num,split==TRUE)
test = subset(google_num,split=FALSE)
set.seed(123)
train.control = trainControl(method = "repeatedcv", 
                              number = 10, repeats = 3)

regsubsets.out <- regsubsets( Reviews ~ .,
                              data = train,
                              nbest = 1,
                              nvmax = NULL,
                              force.in = NULL, force.out = NULL,
                              method = 'forward')
summary(regsubsets.out)
model_1 <- lm(Reviews ~.-Price,data=train)
# use train_validation method to train linear model
model_1_cv= train(Reviews ~.-Price , data = train, method = "lm",
               trControl = train.control)
model_1_cv
```
Here I splitted the original data set into train set and test set, and use foward mothod to see what the best polynomial model is
<br>
<font color='red'>Find</font>
<br>
1. The image tells us that the best polynomial model should have all the variables except 'Price'
<br>
2. The performance of the model is so so, reaching **0.46** in R-squared
<br>

### Polynomial model with interactions
```{r}
# since the pure polynomial model can not fit the data very well, we try to add some interactions into the model
# Since there is strong relationship between Reviews and Installs, we try to add this first
model_2 <- lm(Reviews ~ Size*Installs+`Content Rating`+Genres+Category,data=train)
# model_2_cv considerates the interaction between different features
model_2_cv= train(Reviews ~ Size*Installs*Rating, data = google_num, method = "lm",
               trControl = train.control)
model_2_cv
```
<font color='orange'>**Finding**</font>
<br>
1. The performance of the model is far better than the previous one, reaching **0.60** in R-squared
<br>


### Compare the two models
```{r}
# In order to know the performance of the two models, we use anova function to get F-Test
anova(model_1,model_2)
```
<font color='orange'>**Finding**</font>
<br>
1. The p-value of the model is very low, which means the added parameter -- interaction is pretty important to imrove the performance of the model
<br>

### Visualize the performance of two models
```{r}
# visualize the performance of the model_1_cv
pred_1 <- predict(model_1_cv,test)
google_num <- mutate(google_num, pred_1 = pred_1)
image_3 <- ggplot(data = google_num,aes(x = test$Reviews, y = pred_1)) + geom_point(stat='identity')+ geom_point(stat='identity')+geom_abline(slope= 1,intercept = 0,colour='orange')+xlab("Actual Values")+ylab("Predicted Values")+xlab("Actual Values")+ylab("Predicted Values")+theme_bw()
ggplotly(image_3)
# visualize the performance of the model_2_cv
pred_2 <- predict(model_2_cv,test)
google_num <- mutate(google_num, pred_2 = pred_2)
image_4 <- ggplot(data = google_num,aes(x = test$Reviews, y = pred_2)) + geom_point(stat='identity')+geom_abline(slope= 1,intercept = 0,colour='orange')+xlab("Actual Values")+ylab("Predicted Values")+theme_bw()
ggplotly(image_4) 
```
Here the two images show the different performance of Linear Model 
Apparently the second(with interactions) is fat better than than the first one  

## 4. Tree-based Model Analysis
- Decision Tree
- Confusion Matrix I 
- Random Forest
- Confusion Matrix II

### Decision Tree
```{r,fig.width=7, fig.height=8}
#Since 'Installs' is the dicrete data, we want to predict the installs an App will be(eg:500+, 5000+)
train <- mutate(train,Installs= as.factor(Installs))
# set up a tree classification
classifier_tree = train(Installs ~Reviews+Rating+Category+Size+Genres, data = train, method = "rpart",parms = list(split = "information"),trControl=train.control,tuneLength = 10)
# visualize the tree model
plot(classifier_tree$finalModel)
text(classifier_tree$finalModel)
# use prp function to visualize the tree model
prp(classifier_tree$finalModel, box.palette = "Reds", tweak = 1.2)
# print the detailed information about tree model
print(classifier_tree)
```

### Confusion Matrix I
```{r}
y_pred = predict(classifier_tree, newdata = test)
df<-data.frame(table(test$Installs, y_pred))
df <- mutate(df,Var1 = as.numeric(Var1),y_pred=as.numeric(y_pred),error=Freq)
# cor_image is to visualze the confusion matrix of decision tree model
cor_image <- ggplot(data = df, aes(x=Var1, y=y_pred, fill=error)) + geom_tile() +xlab("Actual Values")+ylab("Predicted Values")+ ggtitle("Confusion Matrix") +theme(plot.title = element_text(hjust = 0.5))
ggplotly(cor_image)
error <- mean(test$Installs != y_pred) # Misclassification error
paste('Accuracy',round(1-error,4))
```

### Random Forest
```{r,warning=FALSE}
mtry = sqrt(ncol(train))
tunegrid = expand.grid(.mtry=mtry)
metric = "Accuracy"
# set up a random forest model to predict installs
classifier_rf = train(Installs ~Reviews+Rating+Category+Size+Genres, data = train, method = "rf",
                      metric=metric, tuneGrid=tunegrid, trControl=train.control,  tuneLength = 5)
# print detailed information about random forest model
print(classifier_rf)
```

### Confusion Matrix II
```{r warning=FALSE}
y_pred = predict(classifier_rf, newdata = test)
# Checking the prediction accuracy
df<-data.frame(table(test$Installs, y_pred)) # Confusion matrix
df <- mutate(df,Var1 = as.numeric(Var1),y_pred=as.numeric(y_pred),error=Freq)
cor_image <- ggplot(data = df, aes(x=Var1, y=y_pred, fill=error)) + geom_tile() +xlab("Actual Values")+ylab("Predicted Values")+ ggtitle("Confusion Matrix") +theme(plot.title = element_text(hjust = 0.5))
ggplotly(cor_image)
error <- mean(test$Installs != y_pred) # Misclassification error
paste('Accuracy',round(1-error,4))
```

## 5. Summary

From the analysis report above, we have got 4 models already. let's do some comparison between the models
<br>
1. Linear Model
<br>
- anova test tells us already that polynomial model with interactions is better than polynomial model
<br>
2. Tree-based Model
<br>
- based on confusion matrix, we could find that Random Forest Model performs better than Decision Tree Modle
<br>
- The Missclassfication error of random forest model is far less than the decision tree model
<br>
- Thus we could make a conclusion that random forest is a better model

<hr>
Potential Next Steps:
<br>
1. evaluate the tree model using more metrics
2. Analyze the categorical variable and see if there are some correlationship among them. (Maybe NLP if possible)

